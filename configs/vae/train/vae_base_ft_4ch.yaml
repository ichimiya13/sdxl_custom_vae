# Fine-tune SDXL VAE (4ch) on your dataset (Base-VAE: recon + KL)

experiment_name: "vae_base_ft_4ch"
seed: 42

data:
  root: "../data/your_dataset_root"
  split_filename: "default_split.yaml"
  train_split: "train"
  val_split: "val"
  label_schema_file: "configs/labels/proposed_schema_mask.yaml"
  # (optional) teacher normalization values for feature loss
  mean: [0.485, 0.456, 0.406]
  std:  [0.229, 0.224, 0.225]

image:
  center_crop_size: 3072
  image_size: 1024

augment:
  hflip_p: 0.5

vae:
  # base_repo_id is used to copy SDXL VAE architecture config
  base_repo_id: "stabilityai/sdxl-vae"
  latent_channels: 4
  init_from_pretrained: true
  dtype: "fp16"   # fp32 for stability if needed
  device: "cuda"
  gpu_ids: [0]

train:
  epochs: 10
  batch_size: 2
  num_workers: 4
  grad_accum_steps: 1
  log_every: 50
  amp: true

optimizer:
  lr: 1.0e-4
  weight_decay: 1.0e-2
  betas: [0.9, 0.999]

loss:
  recon_type: "l1"      # "l1" | "mse"
  recon_weight: 1.0
  kl_weight: 1.0e-6
  feature:
    enabled: false
    weight: 0.0
    type: "l2"          # "l2" | "cosine"
    teacher_checkpoint: "outputs/checkpoints/teacher/best.pt"
    imagenet_pretrained: true

output:
  root_dir: "outputs/checkpoints/vae"
